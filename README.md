# Titanic Survival Prediction

This project involves the analysis of the Titanic dataset to predict passenger survival using machine learning. It is based on the famous [Kaggle Titanic competition](https://www.kaggle.com/c/titanic).

## Project Overview

The goal of this project is to build a predictive model that answers the question: "what sorts of people were more likely to survive?" using passenger data (ie name, age, gender, socio-economic class, etc).

The project is implemented in a Jupyter Notebook (`Untitled.ipynb`) and uses a decision tree classifier to make predictions.

## Files in this Repository

- **`Untitled.ipynb`**: The main Jupyter Notebook containing the data analysis, preprocessing, feature engineering, model training, and prediction generation.
- **`train.csv`**: The training dataset provided by Kaggle.
- **`test.csv`**: The test dataset provided by Kaggle.
- **`gender_submission.csv`**: An example submission file provided by Kaggle.
- **`Submission.csv`**: The final output file containing the predictions generated by the model.

## Dependencies

To run this project, you will need Python installed along with the following libraries:

- pandas
- numpy
- matplotlib
- scikit-learn

You can install the necessary dependencies using pip:

```bash
pip install pandas numpy matplotlib scikit-learn
```

## Methodology

### 1. Data Loading and Exploration
- Loaded the training and test datasets.
- Explored the data structure, types, and missing values.

### 2. Data Preprocessing & Feature Engineering
- **Missing Values**:
    - `Age`: Imputed based on the mean age of passengers with the same "Title" (e.g., Mr, Mrs, Miss).
    - `Embarked`: Imputed with the mode.
    - `Fare`: Imputed with the mean.
    - `Cabin`: Converted to a binary feature (1 if present, 0 if NaN).
- **Feature Extraction**:
    - Extracted `Title` from the `Name` column.
    - Dropped `Name`, `PassengerId`, and `Ticket` columns as they were deemed less relevant for the model after feature extraction.
- **Encoding**:
    - Label Encoding for `Sex`.
    - One-Hot Encoding for categorical features (`Embarked`, `Title`).
- **Scaling**:
    - Used `RobustScaler` to scale the features.

### 3. Modeling
- A **Decision Tree Classifier** (`DecisionTreeClassifier`) from scikit-learn was trained on the processed data.

### 4. Prediction
- The trained model was used to predict survival on the test set.
- The results were saved to `Submission.csv` in the required format for Kaggle submission.

## Usage

1. Clone this repository or download the files.
2. Ensure you have the required datasets (`train.csv`, `test.csv`) in the same directory.
3. Open `Untitled.ipynb` in Jupyter Notebook or JupyterLab.
4. Run all cells to execute the analysis and generate specific predictions.
5. The output `Submission.csv` will be created in the current directory.
